# -*- coding: utf-8 -*-
"""CC_Recruitments_2025_eda.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G3xlJP0rITt789ZR8psuAIQju9qPANd4

#CODECHEF-VIT RECRUITMENTS 2025

# **Step 0: Copy this notebook**

Guidelines:

*   Make a copy of this notebook in your Google Drive
*   
Submit the editted colab notebook as your final submission

# **Step 1: Dataset for this task**

Guidelines: Download the dataset from the link provided and import it into your notebook

Link: https://drive.google.com/file/d/1F65Br7-pkcTZ05d9JG_-qdsKCd_WOyKo/view

# **Step 2: Import necessary libraries**

Guidelines: Import all required libraries here
"""

import numpy as np
import matplotlib.pylab as plt
import seaborn as sb
import pandas as pd

"""# **Step 3: Import Dataset**

Guidelines: Import the csv dataset into a dataframe
"""

data=pd.read_csv("https://drive.google.com/uc?id=1F65Br7-pkcTZ05d9JG_-qdsKCd_WOyKo")

"""# Step 4: Data Cleaning

Guidelines: Prepare the data for analysis
"""

data.head()

data.columns

data.dtypes

print("Number of duplicate rows:", data.duplicated().sum())

missing_values = data.isnull().sum()
print("Missing values in each column:\n", missing_values)

"""# Step 5: Analysis

Guidelines: Perform your analysis here

**Exploratory Data Analysis**
"""

plt.style.use('dark_background')
print(data.describe())

#chart 1
chart_1=data['product_category'].value_counts()\
  .plot(kind='bar',title='product frequency')
chart_1.set_xlabel('product')
chart_1.set_ylabel('frequency')

# chart 2
chart_2=data['purchase_amount'].plot(kind='hist',
                           bins=20,
                           title='purchase amount plot')
chart_2.set_xlabel("purchase_amount")

# chart 3
chart_3=data['purchase_amount'].plot(kind='kde',

                           title='purchase amount plot')
chart_3.set_xlabel("purchase_amount")

# chart 4
chart_4=sb.scatterplot(x='age',
        y='purchase_amount',
        hue="income",
       alpha=0.5,
        size='income',
        data=data,)
plt.show()

# chart 5
plt.hexbin(data['age'], data['purchase_amount'], gridsize=20,  alpha=0.7)
plt.colorbar(label='Density')
plt.xlabel("Age")
plt.ylabel("Purchase Amount")
plt.show()

# chart 6
sb.histplot(data['purchase_amount'], bins=30)
plt.show()

# chart 7
plt.hist2d(data['age'], data['purchase_amount'], bins=(50, 50), cmap='Greens')
plt.colorbar(label='Count')
plt.xlabel("Age")
plt.ylabel("Purchase Amount")
plt.title("2D Histogram of Age vs. Purchase Amount")
plt.show()

# chart 8
plt.style.use('bmh')

sb.pairplot(data,
            vars=['age','income','loyalty_status',
                  'purchase_frequency','purchase_amount','product_category',
                  'satisfaction_score'],
            )
plt.show()

plt.style.use('dark_background')

# chart 9
data_corr = data[['age','income','purchase_amount','promotion_usage','satisfaction_score']].dropna().corr()
sb.heatmap(data_corr, annot=True)

"""**Feature Engineering**"""

# converting purchase frequency into numerical dataset
frequency_mapping = {
    'frequent': 10,
    'occasional': 5,
    'rare': 2
}
# Frequency of purchases
data['purchase_frequency_numeric'] = data['purchase_frequency'].map(frequency_mapping)

# Total spending per customer
data['total_spending_per_customer'] = data['purchase_amount'] * data['purchase_frequency_numeric']

# Customer lifetime value (CLV)  --> average customer lifespan according to internet trends
data['customer-lifespan_value'] = data['purchase_amount'] * data['purchase_frequency_numeric']*4

# Seasonal trends in purchases cannot be determined accurately due to absence of timestamps

data.head()

"""# Step 6: Results and Inferences

Guidelines: List out your inferences here

1) the data has no missing values, NaN values or duplicate entries as each row has its own unique ID
2) the datatypes are correct given in the dataset

**chart 1**

3) electronic products are sold the most, accessories can be bundled to increase revenue

4) beauty products have the lowest sales, advertisement campaign can be run to boost sales

**chart 2 and chart 3**

5) purchases amount frequencies are mostly constant between 4,000 and 12,000 and see a rapid drop off in frequency after.

6) Discounts can be run to enable consumers to spend more

**chart 4**

7) it shows that higher purchase amounts are backed by high income in all age groups

**chart 5**

8) people in their 30s shop the most and do so in all amounts

**chart 6**

9) this shows that most of the revenue is being generated by order prices ranging from 4,000 to 12,000

**chart 7**

10) emphasises the fact that people in their 30s do more spending that any other group

**chart 8**

11)pairplotting reveals patterns in data that can be missed otherwise

**chart 9**

12) a correlation matrix is displayed in the form of a heatmap. it can be seen that purchase amount is heavily dependant on income


------------------------------------------------------------------------
"""